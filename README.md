# WorstNN
This is an attempt to make a Deep Learning Library from scratch for educational purposes. <br><br>
<b>Remember, this is just for understanding how NN works, I don't intend to compete with the likes of TensorFlow and PyTorch (as if I could, lol)<b>

## What to expect?
Implemented the following so far: <br>
<ul>
  <li>Weight Initialization techniques such as Xavier, He and LeCun</li>
  <li>Different loss functions such as MSE, MAE, Huber Loss </li>
  <li>SoftMax Activation Layer</li>
  <li>Activation layers such as ReLU, Sigmoid, Tanh </li>
  <li>Xor Problem</li>
</ul>

## More to come
I plan to add the following
<ul>
  <li>ReLU's variants such as Leaky ReLU, ELU, SELU</li>
  <li>Batch Normalization</li>
  <li>More loss functions such as Cross Entropy Loss</li>
  <li>Convolutional layer</li>
</ul>

## How to use?
1) Clone the repository <br>
2) Run the requirements (really just one requirement, numpy) <br>
3) Run the following <br>
4) <code>python xor.py</code>
